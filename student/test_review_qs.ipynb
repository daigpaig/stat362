{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"response_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Responded at</th>\n",
       "      <th>Presenter</th>\n",
       "      <th>Screen name</th>\n",
       "      <th>Activity type</th>\n",
       "      <th>Activity title</th>\n",
       "      <th>Response options</th>\n",
       "      <th>Your response</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Confirmation message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/25 03:43 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Open ended</td>\n",
       "      <td>What concept from today's lecture is still unc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>activation function</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attendance confirmed at 2025-10-13T15:43:05+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/13/25 03:41 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>Without activation functions in hidden layers,...</td>\n",
       "      <td>True | False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/13/25 03:40 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>In logistic regression, which of the following...</td>\n",
       "      <td>It is a single-neuron neural network | It lear...</td>\n",
       "      <td>The output is computed using a linear activation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/13/25 03:40 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>Which of the following is a key challenge in t...</td>\n",
       "      <td>Excessive convexity | Too many local minima | ...</td>\n",
       "      <td>Excessive convexity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/13/25 03:39 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>What is the output of the forward propagation ...</td>\n",
       "      <td>The gradients of the loss | The activated outp...</td>\n",
       "      <td>The activated output (prediction)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>09/22/25 03:10 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>When you need to install a Python package, wha...</td>\n",
       "      <td>Use pip install package_name in the terminal |...</td>\n",
       "      <td>Use pip install package_name in the terminal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>09/22/25 02:51 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>In VS Code, what's the main difference between...</td>\n",
       "      <td>They are the same thing | The kernel runs note...</td>\n",
       "      <td>The terminal is powered by your operating syst...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attendance confirmed at 2025-09-22T14:51:31+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>09/22/25 02:44 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>Why might someone prefer using VS Code over a ...</td>\n",
       "      <td>VS Code is lighter and customizable | Anaconda...</td>\n",
       "      <td>VS Code is lighter and customizable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attendance confirmed at 2025-09-22T14:44:38+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>09/22/25 02:32 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>Would you prefer to replace the Final Exam wit...</td>\n",
       "      <td>Yes, replace the Final Exam with a Final Proje...</td>\n",
       "      <td>Yes, replace the Final Exam with a Final Project</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attendance confirmed at 2025-09-22T14:32:34+00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>09/17/25 03:35 PM</td>\n",
       "      <td>lizhen9</td>\n",
       "      <td>Daigo M.</td>\n",
       "      <td>Multiple choice</td>\n",
       "      <td>Which sequence did you take?</td>\n",
       "      <td>STAT303 (Python Sequence) | STAT301 (R sequence)</td>\n",
       "      <td>STAT303 (Python Sequence)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attendance confirmed at 2025-09-17T15:35:47+00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Responded at Presenter Screen name    Activity type  \\\n",
       "0   10/13/25 03:43 PM   lizhen9    Daigo M.       Open ended   \n",
       "1   10/13/25 03:41 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "2   10/13/25 03:40 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "3   10/13/25 03:40 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "4   10/13/25 03:39 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "..                ...       ...         ...              ...   \n",
       "60  09/22/25 03:10 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "61  09/22/25 02:51 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "62  09/22/25 02:44 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "63  09/22/25 02:32 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "64  09/17/25 03:35 PM   lizhen9    Daigo M.  Multiple choice   \n",
       "\n",
       "                                       Activity title  \\\n",
       "0   What concept from today's lecture is still unc...   \n",
       "1   Without activation functions in hidden layers,...   \n",
       "2   In logistic regression, which of the following...   \n",
       "3   Which of the following is a key challenge in t...   \n",
       "4   What is the output of the forward propagation ...   \n",
       "..                                                ...   \n",
       "60  When you need to install a Python package, wha...   \n",
       "61  In VS Code, what's the main difference between...   \n",
       "62  Why might someone prefer using VS Code over a ...   \n",
       "63  Would you prefer to replace the Final Exam wit...   \n",
       "64                       Which sequence did you take?   \n",
       "\n",
       "                                     Response options  \\\n",
       "0                                                 NaN   \n",
       "1                                        True | False   \n",
       "2   It is a single-neuron neural network | It lear...   \n",
       "3   Excessive convexity | Too many local minima | ...   \n",
       "4   The gradients of the loss | The activated outp...   \n",
       "..                                                ...   \n",
       "60  Use pip install package_name in the terminal |...   \n",
       "61  They are the same thing | The kernel runs note...   \n",
       "62  VS Code is lighter and customizable | Anaconda...   \n",
       "63  Yes, replace the Final Exam with a Final Proje...   \n",
       "64   STAT303 (Python Sequence) | STAT301 (R sequence)   \n",
       "\n",
       "                                        Your response  Correct  \\\n",
       "0                                 activation function      NaN   \n",
       "1                                                True      NaN   \n",
       "2    The output is computed using a linear activation      NaN   \n",
       "3                                 Excessive convexity      NaN   \n",
       "4                   The activated output (prediction)      NaN   \n",
       "..                                                ...      ...   \n",
       "60       Use pip install package_name in the terminal      NaN   \n",
       "61  The terminal is powered by your operating syst...      NaN   \n",
       "62                VS Code is lighter and customizable      NaN   \n",
       "63   Yes, replace the Final Exam with a Final Project      NaN   \n",
       "64                          STAT303 (Python Sequence)      NaN   \n",
       "\n",
       "                                 Confirmation message  \n",
       "0   Attendance confirmed at 2025-10-13T15:43:05+00...  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "..                                                ...  \n",
       "60                                                NaN  \n",
       "61  Attendance confirmed at 2025-09-22T14:51:31+00...  \n",
       "62  Attendance confirmed at 2025-09-22T14:44:38+00...  \n",
       "63  Attendance confirmed at 2025-09-22T14:32:34+00...  \n",
       "64  Attendance confirmed at 2025-09-17T15:35:47+00...  \n",
       "\n",
       "[65 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What concept from today's lecture is still unclear to you?\n",
      "options: nan\n",
      "my response: activation function\n",
      "Without activation functions in hidden layers, a neural network becomes equivalent to a linear model.\n",
      "options: True | False\n",
      "my response: True\n",
      "In logistic regression, which of the following is NOT true?\n",
      "options: It is a single-neuron neural network | It learns weights and bias | The output is computed using a linear activation | It uses the sigmoid function\n",
      "my response: The output is computed using a linear activation\n",
      "Which of the following is a key challenge in training deep neural networks?\n",
      "options: Excessive convexity | Too many local minima | Easy optimization landscape | No need for gradient computation\n",
      "my response: Excessive convexity\n",
      "What is the output of the forward propagation step in logistic regression?\n",
      "options: The gradients of the loss | The activated output (prediction) | The input tensor | The update rule for weights\n",
      "my response: The activated output (prediction)\n",
      "In a single neuron network, the activation function:\n",
      "options: Adds new parameters to the model | Makes the model linear | Introduces non-linearity to the model | . Removes the bias term\n",
      "my response: Introduces non-linearity to the model\n",
      "What makes deep learning models different from traditional machine learning models?\n",
      "options: They require manual feature engineering | They cannot learn non-linear patterns | They perform automatic feature extraction | They are always interpretable\n",
      "my response: They perform automatic feature extraction\n",
      "What is one concept from today's lecture that is still unclear or confusing to you?\n",
      "options: nan\n",
      "my response: penalty term\n",
      "The Ridge regression cost function is:\n",
      "options: MSE + Œª Œ£|Œ≤‚±º| | MSE + Œª Œ£Œ≤‚±º¬≤ | MSE- Œª Œ£Œ≤‚±º¬≤ | MSE √ó Œª Œ£Œ≤‚±º¬≤\n",
      "my response: MSE + Œª Œ£Œ≤‚±º¬≤\n",
      "The Lasso regression cost function is:\n",
      "options: MSE + Œª Œ£|Œ≤‚±º| | MSE + Œª Œ£Œ≤‚±º¬≤ | RSS - Œª Œ£|Œ≤‚±º| | RSS / Œª Œ£|Œ≤‚±º|\n",
      "my response: RSS - Œª Œ£|Œ≤‚±º|\n",
      "Which statement about the bias-variance tradeoff is correct?\n",
      "options: Regularization decreases bias and decreases variance | Regularization increases bias and increases variance | Regularization decreases bias and increases variance | Regularization increases bias and decreases variance\n",
      "my response: Regularization decreases bias and increases variance\n",
      "Which regularization method uses L2 penalty?\n",
      "options: Lasso | Ridge | Elastic Net only | None of the above\n",
      "my response: Ridge\n",
      "What is a key difference between Ridge and Lasso regression?\n",
      "options: Ridge can shrink coefficients to exactly zero, Lasso cannot | Lasso can shrink coefficients to exactly zero, Ridge cannot | Ridge works only with categorical variables | Lasso requires more computational power\n",
      "my response: Lasso can shrink coefficients to exactly zero, Ridge cannot\n",
      "What happens when Œª = 0 in regularized regression?\n",
      "options: All coefficients become zero | The model becomes equivalent to ordinary least squares | The model cannot be trained | Only the intercept is estimated\n",
      "my response: The model becomes equivalent to ordinary least squares\n",
      "What happens when Œª ‚Üí ‚àû (very large)?\n",
      "options: All coefficients approach zero (except intercept) | All coefficients become very large | The model becomes equivalent to OLS | Only one coefficient survives\n",
      "my response: All coefficients approach zero (except intercept)\n",
      "In Ridge regression, as Œª increases, the model:\n",
      "options: Becomes more complex | Fits training data better | Becomes simpler/more constrained | Uses more features\n",
      "my response: Becomes simpler/more constrained\n",
      "Before applying regularization, you should:\n",
      "options: Remove all outliers | Standardize/scale the features | Reduce the number of samples | Increase the number of features\n",
      "my response: Standardize/scale the features\n",
      "What is the primary purpose of regularization in linear regression?\n",
      "options: To increase model complexity | To prevent underfitting | To speed up training time | To prevent overfitting\n",
      "my response: To prevent overfitting\n",
      "You want to identify the 10 most important features from 50 candidates. Which method?\n",
      "options: Ridge Regression | Lasso Regression | Ordinary Least Squares | Polynomial Regression\n",
      "my response: Lasso Regression\n",
      "Which metric in linear regression is best for selecting the optimal Œª using cross-validation?\n",
      "options: Training R¬≤ | Training RMSE | Cross-validated RMSE or R¬≤ | Number of non-zero coefficients\n",
      "my response: Cross-validated RMSE or R¬≤\n",
      "In a regularization path plot for Lasso, what happens to coefficients as Œª increases?\n",
      "options: All coefficients increase together | Coefficients gradually shrink, with some becoming zero at different Œª values | All coefficients become zero at the same Œª value | Coefficients oscillate randomly\n",
      "my response: Coefficients gradually shrink, with some becoming zero at different Œª values\n",
      "You fit Ridge with different Œª values. Which result is most likely correct?\n",
      "options: Larger Œª ‚Üí smaller training error | Larger Œª ‚Üí larger training error | Œª has no effect on training error | Larger Œª ‚Üí more coefficients become zero\n",
      "my response: Larger Œª ‚Üí larger training error\n",
      "After applying Lasso, 40 out of 50 coefficients are zero. This suggests:\n",
      "options: The model is underfitting | Most features are not useful for prediction | You need to decrease Œª | The model is broken\n",
      "my response: Most features are not useful for prediction\n",
      "Your model shows: Train R¬≤ = 0.95, Test R¬≤ = 0.60. What does this indicate?\n",
      "options: Underfitting | Overfitting | Perfect fit | Need more features\n",
      "my response: Overfitting\n",
      "The closed-form solution for linear regression requires computing  ( ùëã ‚ä§ ùëã ) ‚àí 1  , which can be costly and numerically unstable for large  ùëõ .\n",
      "options: True | False\n",
      "my response: True\n",
      "Which description of SGD/mini-batch is correct?\n",
      "options: SGD updates on the full dataset each step | Mini-batch updates use a small subset each step (common in practice) | SGD always converges faster than batch GD | Mini-batch is only for classification\n",
      "my response: Mini-batch updates use a small subset each step (common in practice)\n",
      "When is closed form limiting?\n",
      "options: When adding regularization terms | When  ùëõ n is tiny | When learning rate is unknown | When feature scale varies\n",
      "my response: When adding regularization terms\n",
      "Vectorized cost: Let  ùëí = ùëã ùë§ + ùëè 1 ‚àí ùë¶ . Which equals the MSE cost  ùêΩ ( ùë§ , ùëè ) ? (T is transpose)\n",
      "options: 1 /ùëö  e ‚ä§ e | 1 /2ùëö  e ‚ä§ e | 1 /2  e ‚ä§ e | e ‚ä§ e\n",
      "my response: 1 /2ùëö  e ‚ä§ e\n",
      "Augmented form (move bias into weights): Which expression is correct after augmenting with a column of ones?\n",
      "options: (an image) | (an image) | (an image) | (an image)\n",
      "my response: (an image)\n",
      "Many predictions at once: For design matrix X (m√ón) and w (n,), which computes predictions for all m rows?\n",
      "options: w @ X + b | X @ w + b | np.dot(w, X) | X * w + b (element-wise)\n",
      "my response: X @ w + b\n",
      "Single prediction in NumPy: For weight vector w, input x, and bias b, which computes  ùëì ùë§ , ùëè ( ùë• ) ?\n",
      "options: w @ x.T + b | np.dot(w, x) + b | x @ w + b (with x shape (n, m)) | np.sum(w * x) (no bias)\n",
      "my response: x @ w + b (with x shape (n, m))\n",
      "Why is feature scaling essential for gradient descent?\n",
      "options: It changes the cost function | It speeds convergence and stabilizes updates | It removes the need for a learning rate | It guarantees zero training error\n",
      "my response: It speeds convergence and stabilizes updates\n",
      "What was the 'muddiest point' for you in today's lecture‚Äîthe concept or step that felt the most unclear or confusing?\n",
      "options: nan\n",
      "my response: the performance differences between gradient descent and closed form\n",
      "When training a linear regression model with gradient descent, you decide to scale your features using StandardScaler. Which of the following statements is incorrect?\n",
      "options: Feature scaling allows a larger learning rate to be used, because all features are on a similar scale. | You should call .fit_transform() on both the training and the test set to ensure proper scaling. | Without scaling, gradient descent may converge very slowly or not converge at all. | The correct workflow is to fit the scaler on the training data, and then transform both the training and the test data with it.\n",
      "my response: You should call .fit_transform() on both the training and the test set to ensure proper scaling.\n",
      "Which statement about vectorization in NumPy is true?\n",
      "options: It is slower than loops for large datasets. | It is used mainly for graphics rendering. | It simplifies code and improves performance. | It prevents the need for feature scaling.\n",
      "my response: It simplifies code and improves performance.\n",
      "If your features are on vastly different scales, gradient descent will most likely:\n",
      "options: Converge faster | Diverge immediately | Oscillate or zig-zag, slowing convergence | Ignore small features completely\n",
      "my response: Oscillate or zig-zag, slowing convergence\n",
      "Why is feature scaling important for gradient descent?\n",
      "options: It increases model accuracy. | It ensures features follow a standard distribution. | It prevents large feature values from dominating gradient updates. | It eliminates the need for a cost function.\n",
      "my response: It prevents large feature values from dominating gradient updates.\n",
      "Which Python library's linear regression implementation uses gradient descent under the hood?\n",
      "options: scikit-learn | statsmodels | SGDRegressor | LinearRegression\n",
      "my response: SGDRegressor\n",
      "What is most likely to happen if the learning rate in gradient descent is set too small?\n",
      "options: The algorithm will overshoot the minimum and diverge. | The algorithm will converge quickly but may get stuck in a local minimum. | The algorithm will converge slowly and take a long time to reach the minimum. | The gradient will become zero and stop updating the parameters immediately.\n",
      "my response: The algorithm will converge slowly and take a long time to reach the minimum.\n",
      "Have you ever ran into this warning when using logistic regression\n",
      "options: Yes | No\n",
      "my response: Yes\n",
      "If you train a Logistic Regression model on the same dataset using statsmodels and scikit-learn, and both are set to consistently include the intercept, will you always get exactly the same model parameters?\n",
      "options: Yes, both use the same maximum likelihood estimation method, so the coefficients will always match exactly. | No, because statsmodels uses maximum likelihood estimation, while scikit-learn uses numerical optimization with solvers (e.g., lbfgs, liblinear), which can yield slight differences. | No, because scikit-learn applies regularization (penalty) by default unless explicitly turned off. | Yes, as long as you disable regularization in scikit-learn,  the results will be the same (up to numerical tolerance).\n",
      "my response: Yes, as long as you disable regularization in scikit-learn,  the results will be the same (up to numerical tolerance).\n",
      "If you train a Linear Regression model on the same dataset using statsmodels and scikit-learn, and both are set to consistently include the intercept, will you always get exactly the same model parameters?\n",
      "options: No, because statsmodels and scikit-learn standardize the data differently. | No, because scikit-learn applies regularization by default. | No, because statsmodels and scikit-learn use different optimization algorithms. | Yes, both use the Ordinary Least Squares (OLS) closed-form solution, so the coefficients will match.\n",
      "my response: No, because statsmodels and scikit-learn use different optimization algorithms.\n",
      "Which of the following machine learning models are parametric?\n",
      "options: Linear and logistic regression | linear regression and k nearest neighbors | linear regression and decision tree | all of them are parametric | ONly k-nearest neighbors and decision tree\n",
      "my response: Linear and logistic regression\n",
      "What's still unclear from today's deck? Answer in 1‚Äì3 words (topic or term).\n",
      "options: nan\n",
      "my response: appropriate folder structure\n",
      "How to specify your file path?\n",
      "options: data/trips.csv | ../data/trips.csv | ./data/trips.csv\n",
      "my response: ../data/trips.csv\n",
      "Poetry tends to be better for pure-Python dependency resolution than Conda.\n",
      "options: True | False\n",
      "my response: True\n",
      "Conda vs. Poetry ‚Äî Choose Poetry when you mainly need:\n",
      "options: CUDA + system libs | Pure-Python project with lockfiles/publishing | Managing non-python packages | System PATH editing\n",
      "my response: Pure-Python project with lockfiles/publishing\n",
      "Poetry install from a TOML ‚Äî To create env from a project's pyproject.toml, use:\n",
      "options: poetry build | poetry run | poetry install | poetry lock\n",
      "my response: poetry install\n",
      "Why python -m pip install\n",
      "options: It‚Äôs faster | It installs GPU support | It targets the intended interpreter/env\n",
      "my response: It targets the intended interpreter/env\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"response_history.csv\")\n",
    "\n",
    "counter = 0\n",
    "while counter < len(df):\n",
    "    # Print question\n",
    "    print(df.iloc[counter][\"Activity title\"])\n",
    "    # Print options\n",
    "    print(\"options:\", df.iloc[counter][\"Response options\"])\n",
    "    _ = input(\"> \")  # Wait for user to think/type something'\n",
    "    # Print recorded response\n",
    "    print(\"my response:\", df.iloc[counter][\"Your response\"])\n",
    "    # Ask if user wants to continue or quit\n",
    "    ans = input(\"(Press Enter for next, or '$' to stop) \")\n",
    "\n",
    "    if ans.strip() == \"$\":\n",
    "        break\n",
    "\n",
    "    counter += 1  # move to the next question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
