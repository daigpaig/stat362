{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b7586d88-1b36-42f6-9cf4-2d01cf6c5204",
   "metadata": {
    "id": "b7586d88-1b36-42f6-9cf4-2d01cf6c5204",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Quiz 1: Gradient Descent with Simple Linear Regression Using For Loop\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    number-sections: true\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a8da5-27b2-4eef-84a0-70a354fcb50b",
   "metadata": {
    "id": "038a8da5-27b2-4eef-84a0-70a354fcb50b"
   },
   "source": [
    "## Tools and Libraries\n",
    "\n",
    "In this quiz, we will make use of:\n",
    "\n",
    "- **NumPy** - A fundamental library for scientific computing in Python, providing support for arrays, mathematical functions, and linear algebra operations\n",
    "- **Matplotlib** - A comprehensive library for creating static, animated, and interactive visualizations in Python\n",
    "- **Built-in Python functions** - Including `copy` for creating deep copies of objects and `math` for mathematical operations\n",
    "- **Jupyter notebook magic commands** - Such as `%matplotlib inline` for displaying plots inline and `%autoreload` for automatically reloading modules\n",
    "\n",
    "## Key Python Concepts Used\n",
    "- For loops for iterative computations\n",
    "- NumPy arrays for efficient numerical operations\n",
    "- Function definitions and parameter passing\n",
    "- Gradient descent algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cc0416-20b6-4d53-88ce-b45b6f0a4acb",
   "metadata": {
    "id": "a6cc0416-20b6-4d53-88ce-b45b6f0a4acb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153d9384-e918-4346-b704-fe59b219b57c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "153d9384-e918-4346-b704-fe59b219b57c",
    "outputId": "dce00b22-ea03-4f04-c4c1-0bb6a3208d29"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ed48f",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "### Real Estate Price Prediction Challenge\n",
    "\n",
    "Imagine you're a real estate analyst tasked with building a model to predict house prices based on square footage. You have access to a small but valuable dataset from recent sales in your area.\n",
    "\n",
    "**Our Dataset:**\n",
    "We have two recent home sales that will serve as our training data:\n",
    "\n",
    "| House | Size (1000 sqft) | Price (1000s of dollars) | Details |\n",
    "|-------|------------------|--------------------------|---------|\n",
    "| A     | 1.0              | 300                      | 1000 sqft â†’ $300,000 |\n",
    "| B     | 2.0              | 500                      | 2000 sqft â†’ $500,000 |\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this quiz, you will:\n",
    "\n",
    "1. **Implement from scratch** the three core components of gradient descent:\n",
    "   - Cost function computation\n",
    "   - Gradient calculation  \n",
    "   - Parameter optimization loop\n",
    "2. **Apply mathematical concepts** using Python for loops (no vectorization shortcuts!)\n",
    "3. **Visualize the learning process** through cost function plots\n",
    "4. **Make predictions** using your trained model\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Your mission is to find the optimal parameters $(w, b)$ for the linear model:\n",
    "$$f_{w,b}(x) = wx + b$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x$ = house size in thousands of square feet\n",
    "- $f_{w,b}(x)$ = predicted price in thousands of dollars\n",
    "- $w$ = slope (price increase per 1000 sqft)\n",
    "- $b$ = y-intercept (base price)\n",
    "\n",
    "**Question to ponder:** Looking at our data, can you estimate what the slope $w$ might be? What does this represent in real-world terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75428a4e-f708-4a61-9a56-288af4599b4a",
   "metadata": {
    "id": "75428a4e-f708-4a61-9a56-288af4599b4a"
   },
   "outputs": [],
   "source": [
    "# Create our data set\n",
    "x_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300.0, 500.0])   #target value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba9a7b-7ee9-49fd-953a-e0fd1f7b2e0c",
   "metadata": {
    "id": "e3ba9a7b-7ee9-49fd-953a-e0fd1f7b2e0c"
   },
   "source": [
    "## Linear Regression Fundamentals\n",
    "\n",
    "In this quiz, you will fit the linear regression parameters $(w,b)$ to your dataset using gradient descent from scratch.\n",
    "\n",
    "### The Linear Model\n",
    "\n",
    "The model function for linear regression maps from input `x` (house size) to output `y` (house price):\n",
    "\n",
    "$$f_{w,b}(x) = wx + b$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $w$ is the **weight** (or slope) - how much the price changes per unit of size\n",
    "- $b$ is the **bias** (or y-intercept) - the base price when size = 0\n",
    "- $x$ is the input feature (house size in 1000s of sqft)\n",
    "- $f_{w,b}(x)$ is the predicted output (house price in 1000s of dollars)\n",
    "\n",
    "### Finding the Best Parameters\n",
    "\n",
    "To train a linear regression model, you need to find the optimal $(w,b)$ parameters:\n",
    "\n",
    "1. **Cost Function Evaluation**: Compare different parameter choices using a cost function $J(w,b)$\n",
    "   - $J(w,b)$ measures how well your model fits the data\n",
    "   - Lower cost = better fit\n",
    "   \n",
    "2. **Optimization Goal**: Find $(w,b)$ that minimizes $J(w,b)$\n",
    "   - The \"best\" parameters are those with the smallest cost\n",
    "   - This gives you the line that best fits your training data\n",
    "\n",
    "3. **Gradient Descent**: Use this iterative algorithm to find optimal parameters\n",
    "   - Start with initial guesses for $w$ and $b$\n",
    "   - Repeatedly adjust parameters in the direction that reduces cost\n",
    "   - Each step moves closer to the optimal values\n",
    "\n",
    "### The Power of Your Model\n",
    "\n",
    "Once trained, your linear regression model becomes a **prediction machine**:\n",
    "\n",
    "- **Input**: Square footage of any house\n",
    "- **Output**: Estimated selling price\n",
    "- **Application**: Help real estate agents, buyers, and sellers make informed decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817cde90-255a-4bf0-945a-a904c5008e84",
   "metadata": {
    "id": "817cde90-255a-4bf0-945a-a904c5008e84"
   },
   "source": [
    "## Implement Gradient Descent From Scratch\n",
    "\n",
    "Now comes the exciting part! You will implement the gradient descent algorithm step by step using **for loops only** - no vectorized operations allowed. This approach will help you understand exactly what's happening at each step.\n",
    "\n",
    "### The Three Essential Functions\n",
    "\n",
    "You'll build three interconnected functions that work together:\n",
    "\n",
    "1. **`compute_cost`** - Measures how well your current parameters fit the data\n",
    "2. **`compute_gradient`** - Calculates which direction to adjust your parameters  \n",
    "3. **`gradient_descent`** - Orchestrates the iterative optimization process\n",
    "\n",
    "### Function Overview\n",
    "\n",
    "   ```\n",
    "   Input: Training Data (x, y)\n",
    "      â†“\n",
    "   compute_cost(w, b) â†’ Current fit quality\n",
    "      â†“\n",
    "   compute_gradient(w, b) â†’ Direction to improve\n",
    "      â†“  \n",
    "   gradient_descent() â†’ New improved (w, b)\n",
    "      â†“\n",
    "   Repeat until convergence!\n",
    "   ```\n",
    "\n",
    "### Implementation Strategy\n",
    "\n",
    "**Why for loops?** While NumPy vectorization is faster, using explicit loops helps you:\n",
    "\n",
    "- Understand each calculation step-by-step\n",
    "- Build intuition for how gradient descent actually works\n",
    "- Appreciate vectorization when you use it later!\n",
    "\n",
    "### Coding Conventions\n",
    "\n",
    "To keep our code readable and mathematically accurate:\n",
    "\n",
    "- **Partial derivatives**: Variables representing $\\frac{\\partial J(w,b)}{\\partial b}$ will be named `dj_db`\n",
    "- **Naming pattern**: `dj_d[parameter]` where `[parameter]` is the variable we're taking the derivative with respect to\n",
    "- **Abbreviation**: \"w.r.t\" = \"With Respect To\" (common mathematical shorthand)\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- $\\frac{\\partial J(w,b)}{\\partial w}$ â†’ `dj_dw` (derivative of J with respect to w)  \n",
    "- $\\frac{\\partial J(w,b)}{\\partial b}$ â†’ `dj_db` (derivative of J with respect to b)\n",
    "\n",
    "### Ready to Code?\n",
    "\n",
    "Let's implement each function one by one, building your gradient descent algorithm from the ground up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7777fd-33b5-43ef-b973-3bcd3f89141b",
   "metadata": {
    "id": "3c7777fd-33b5-43ef-b973-3bcd3f89141b"
   },
   "source": [
    "### Function 1: Compute_Cost\n",
    "\n",
    "The cost function is your **quality meter** - it tells you how well your current parameters $(w,b)$ fit the training data. Lower cost means better fit!\n",
    "\n",
    "#### Understanding the Cost Function\n",
    "\n",
    "The Mean Squared Error (MSE) cost function measures the average squared difference between predictions and actual values:\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "**Breaking it down:**\n",
    "\n",
    "- $f_{w,b}(x^{(i)}) = wx^{(i)} + b$ â†’ Your model's prediction for house $i$\n",
    "- $y^{(i)}$ â†’ Actual selling price for house $i$  \n",
    "- $(f_{w,b}(x^{(i)}) - y^{(i)})^2$ â†’ Squared error for house $i$\n",
    "- $\\frac{1}{2m}$ â†’ Average over all $m$ examples (the $\\frac{1}{2}$ simplifies calculus later!)\n",
    "\n",
    "#### Task 1: compute the cost\n",
    "\n",
    "Complete the `compute_cost` function using for loops to:\n",
    "\n",
    "**Step 1:** For each training example $i$, compute:\n",
    "\n",
    "- **Prediction:** $f_{wb}(x^{(i)}) = wx^{(i)} + b$\n",
    "- **Individual cost:** $cost^{(i)} = (f_{wb}(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "**Step 2:** Sum all individual costs and return the total:\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} cost^{(i)}$$\n",
    "\n",
    "**Key insight:** You're measuring how \"wrong\" your predictions are on average. The squaring ensures:\n",
    "\n",
    "- All errors are positive (no cancellation between over/under predictions)\n",
    "- Larger errors are penalized more heavily than small errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aed6956-9545-48f9-8d7a-644c1cc1d35e",
   "metadata": {
    "id": "9aed6956-9545-48f9-8d7a-644c1cc1d35e"
   },
   "outputs": [],
   "source": [
    "# compute_cost\n",
    "\n",
    "def compute_cost(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the cost function for linear regression using Mean Squared Error.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): Shape (m,) - Input features (house sizes in 1000s sqft)\n",
    "        y (ndarray): Shape (m,) - Target values (house prices in 1000s dollars)\n",
    "        w (scalar): Weight parameter (slope of the line)\n",
    "        b (scalar): Bias parameter (y-intercept of the line)\n",
    "\n",
    "    Returns:\n",
    "        total_cost (float): The cost J(w,b) representing how well the parameters\n",
    "                           fit the training data. Lower cost = better fit.\n",
    "    \"\"\"\n",
    "    # Number of training examples\n",
    "    m = x.shape[0]\n",
    "\n",
    "    # Initialize total cost\n",
    "    total_cost = 0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Variable to accumulate the sum of squared errors\n",
    "    cost_sum = 0\n",
    "    \n",
    "    # Loop through each training example\n",
    "    for i in range(m):\n",
    "        \n",
    "        # Step 1: Calculate prediction using linear model\n",
    "        f_wb = w * x[i] + b\n",
    "        \n",
    "        # Step 2: Calculate squared error for this example\n",
    "        error = f_wb - y[i]\n",
    "        cost = error ** 2\n",
    "        \n",
    "        # Step 3: Add this example's cost to running sum\n",
    "        cost_sum += cost\n",
    "    \n",
    "    # Step 4: Calculate final cost using MSE \n",
    "    total_cost = (1 / m) * cost_sum\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad95f76-8295-423b-9337-594bc7fc8c73",
   "metadata": {
    "id": "dad95f76-8295-423b-9337-594bc7fc8c73"
   },
   "source": [
    "#### Test Your Implementation\n",
    "\n",
    "Great job! Now let's verify that your `compute_cost` function works correctly. \n",
    "\n",
    "Run the test code below to check your implementation. The test uses initial parameters `w=2` and `b=1` to see how well they fit our training data.\n",
    "\n",
    "**What to expect:**\n",
    "\n",
    "- The function should return a `float` type\n",
    "- The cost value tells you how well these parameters fit the data\n",
    "- Higher cost = worse fit, Lower cost = better fit\n",
    "\n",
    "**For the Canvas quiz:** Record the exact cost value that your function returns - you'll need this number to complete the quiz questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69e4ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "Cost at initial w: 166617.000\n"
     ]
    }
   ],
   "source": [
    "# Compute cost with some initial values for paramaters w, b\n",
    "initial_w = 2\n",
    "initial_b = 1\n",
    "\n",
    "cost = compute_cost(x_train, y_train, initial_w, initial_b)\n",
    "print(type(cost))\n",
    "print(f'Cost at initial w: {cost:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01902b",
   "metadata": {},
   "source": [
    "### Function 2: Compute_Gradient\n",
    "\n",
    "The gradient tells you **which direction to move** your parameters to reduce the cost. Think of it as a compass pointing toward better parameter values!\n",
    "\n",
    "#### Understanding Gradients\n",
    "\n",
    "Gradients are partial derivatives that measure how the cost function changes when you slightly adjust each parameter:\n",
    "\n",
    "- $\\frac{\\partial J(w,b)}{\\partial w}$ â†’ How much does cost change if we increase $w$ slightly?\n",
    "- $\\frac{\\partial J(w,b)}{\\partial b}$ â†’ How much does cost change if we increase $b$ slightly?\n",
    "\n",
    "**The math behind it:** For our cost function $J(w,b) = \\frac{1}{2m} \\sum (f_{w,b}(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "The partial derivatives work out to:\n",
    "$$\\frac{\\partial J(w,b)}{\\partial b}^{(i)} = (f_{w,b}(x^{(i)}) - y^{(i)})$$\n",
    "$$\\frac{\\partial J(w,b)}{\\partial w}^{(i)} = (f_{w,b}(x^{(i)}) - y^{(i)}) \\cdot x^{(i)}$$\n",
    "\n",
    "#### Task 2: compute the gradient\n",
    "\n",
    "Complete the `compute_gradient` function using for loops to:\n",
    "\n",
    "**Step 1:** For each training example $i$, compute:\n",
    "\n",
    "- **Prediction:** $f_{wb}(x^{(i)}) = wx^{(i)} + b$\n",
    "- **Error:** $error^{(i)} = f_{wb}(x^{(i)}) - y^{(i)}$ \n",
    "- **Gradient contributions:**\n",
    "  - For $b$: $\\frac{\\partial J}{\\partial b}^{(i)} = error^{(i)}$\n",
    "  - For $w$: $\\frac{\\partial J}{\\partial w}^{(i)} = error^{(i)} \\cdot x^{(i)}$\n",
    "\n",
    "**Step 2:** Average all gradient contributions:\n",
    "$$\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum\\limits_{i=0}^{m-1} \\frac{\\partial J}{\\partial b}^{(i)}$$\n",
    "$$\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum\\limits_{i=0}^{m-1} \\frac{\\partial J}{\\partial w}^{(i)}$$\n",
    "\n",
    "**Key insight:** \n",
    "\n",
    "- **Positive gradient** â†’ Increase parameter to reduce cost\n",
    "- **Negative gradient** â†’ Decrease parameter to reduce cost  \n",
    "- **Larger magnitude** â†’ Steeper slope, bigger adjustment needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ddb976-e672-4c7c-bf17-7f5f3b9b459f",
   "metadata": {
    "id": "64ddb976-e672-4c7c-bf17-7f5f3b9b459f"
   },
   "outputs": [],
   "source": [
    "# compute_gradient\n",
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression\n",
    "    Args:\n",
    "      x (ndarray): Shape (m,) Input to the model (house sizes)\n",
    "      y (ndarray): Shape (m,) Label (house prices)\n",
    "      w, b (scalar): Parameters of the model\n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameter w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b\n",
    "     \"\"\"\n",
    "\n",
    "    # Number of training examples\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # Initialize gradient accumulators\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Loop through each training example\n",
    "    for i in range(m):\n",
    "        \n",
    "        # Step 1: Calculate prediction for example i\n",
    "        f_wb = w * x[i] + b\n",
    "        \n",
    "        # Step 2: Calculate the error (prediction - actual)\n",
    "        error = f_wb - y[i]\n",
    "        \n",
    "        # Step 3: Calculate gradient contributions for this example\n",
    "        dj_db_i = error\n",
    "        \n",
    "        dj_dw_i = error * x[i]\n",
    "        \n",
    "        # Step 4: Accumulate the gradients\n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i\n",
    "    \n",
    "    # Step 5: Average the gradients over all examples\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e24e3-1fce-469f-97ef-9a63a9ca9254",
   "metadata": {
    "id": "d58e24e3-1fce-469f-97ef-9a63a9ca9254"
   },
   "source": [
    "#### Test Your Gradient Function\n",
    "\n",
    "Excellent work! Now let's test your `compute_gradient` function to see if it correctly calculates the gradients.\n",
    "\n",
    "Run the test below to verify your implementation. We'll start with parameters `w=0` and `b=0` to see what gradients your function computes.\n",
    "\n",
    "**What to expect:**\n",
    "\n",
    "- The function should return two values: `dj_dw` and `dj_db`\n",
    "- These represent the direction and magnitude to adjust each parameter\n",
    "- The values tell you how to improve your model's fit to the data\n",
    "\n",
    "**For the Canvas quiz:** Record the exact gradient values that your function returns - you'll need these numbers for the quiz questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a8cd99-37b3-46e8-bad9-c8194fadf8a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33a8cd99-37b3-46e8-bad9-c8194fadf8a9",
    "outputId": "41ef6c10-376f-4d7f-a8a6-b7eac22013a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at initial w, b (zeros): -650.0 -400.0\n"
     ]
    }
   ],
   "source": [
    "# Compute and display gradient with w and b initialized to zeroes\n",
    "initial_w = 0\n",
    "initial_b = 0\n",
    "\n",
    "tmp_dj_dw, tmp_dj_db = compute_gradient(x_train, y_train, initial_w, initial_b)\n",
    "print('Gradient at initial w, b (zeros):', tmp_dj_dw, tmp_dj_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d647d55",
   "metadata": {},
   "source": [
    "### Function 3: Do Gradient Decent\n",
    "\n",
    "After you implemented `compute_gradient` which calculates $\\frac{\\partial J(w)}{\\partial w}$, $\\frac{\\partial J(w)}{\\partial b}$ , you will next implement the gradient descent for parameters $w, b$ for linear regression.\n",
    "\n",
    "As described in the lecture, the gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \\phantom {0000} b := b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b} \\newline       \\; & \\phantom {0000} w := w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w}   \\; &\n",
    "\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $w, b$ are both updated simultaniously and where  \n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) -y^{(i)})x^{(i)} \n",
    "$$\n",
    "\n",
    "* $m$ is the number of training examples in the dataset\n",
    "\n",
    "    \n",
    "*  $f_{w,b}(x^{(i)})$ is the model's prediction, while $y^{(i)}$, is the target value\n",
    "a.lgorithm.\n",
    "\n",
    "#### Task 3: do gradient descent\n",
    "\n",
    "Please complete the `gradient_descent` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf8d754-3045-4492-908b-9f74df6c70fd",
   "metadata": {
    "id": "ddf8d754-3045-4492-908b-9f74df6c70fd"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to optimize parameters w and b\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray): Shape (m,) - Input features (house sizes)\n",
    "      y (ndarray): Shape (m,) - Target values (house prices)  \n",
    "      w_in, b_in (scalar): Initial parameter values\n",
    "      cost_function: Function to compute cost J(w,b)\n",
    "      gradient_function: Function to compute gradients dJ/dw, dJ/db\n",
    "      alpha (float): Learning rate - how big steps to take\n",
    "      num_iters (int): Number of iterations to run\n",
    "    Returns:\n",
    "      w, b (scalar): Optimized parameter values\n",
    "      J_history (list): Cost at each iteration (for plotting)\n",
    "      w_history (list): Parameter values at each iteration (for plotting)\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of training examples\n",
    "    m = len(x)\n",
    "    \n",
    "    # Arrays to store history for plotting learning curves\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    # Initialize parameters (make copies to avoid modifying inputs)\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Main gradient descent loop\n",
    "    for i in range(num_iters):\n",
    "        \n",
    "        # Step 1: Compute gradients using your gradient function\n",
    "        dj_dw, dj_db = compute_gradient(x, y, w, b)\n",
    "        \n",
    "        # Step 2: Update parameters using gradient descent rule\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "        # Step 3: Compute and save cost for this iteration (for plotting)\n",
    "        if i < 100000:  # Prevent memory issues for very long runs\n",
    "            cost = compute_cost(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "            w_history.append([w, b])\n",
    "        \n",
    "        # Print progress every 10% of iterations\n",
    "        if i % math.ceil(num_iters/10) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f} \",\n",
    "                  f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "                  f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return w, b, J_history, w_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48d490-3ec7-4ade-8c81-5fc561aadc0f",
   "metadata": {
    "id": "ee48d490-3ec7-4ade-8c81-5fc561aadc0f"
   },
   "source": [
    "\n",
    "####  Find Your Optimal Parameters via your gradient descent\n",
    "\n",
    "Now let's run your gradient descent algorithm to discover the optimal values of $w$ and $b$ for our real estate dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0951a1-073d-4895-9bb1-3b7668e2cde3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e0951a1-073d-4895-9bb1-3b7668e2cde3",
    "outputId": "22154047-5730-4eac-a25a-d887ab7ed8a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 158549.62  dj_dw: -6.500e+02, dj_db: -4.000e+02   w:  6.500e+00, b: 4.00000e+00\n",
      "Iteration 1000: Cost     6.83  dj_dw: -3.712e-01, dj_db:  6.007e-01   w:  1.949e+02, b: 1.08228e+02\n",
      "Iteration 2000: Cost     1.59  dj_dw: -1.789e-01, dj_db:  2.895e-01   w:  1.975e+02, b: 1.03966e+02\n",
      "Iteration 3000: Cost     0.37  dj_dw: -8.625e-02, dj_db:  1.396e-01   w:  1.988e+02, b: 1.01912e+02\n",
      "Iteration 4000: Cost     0.09  dj_dw: -4.158e-02, dj_db:  6.727e-02   w:  1.994e+02, b: 1.00922e+02\n",
      "Iteration 5000: Cost     0.02  dj_dw: -2.004e-02, dj_db:  3.243e-02   w:  1.997e+02, b: 1.00444e+02\n",
      "Iteration 6000: Cost     0.00  dj_dw: -9.660e-03, dj_db:  1.563e-02   w:  1.999e+02, b: 1.00214e+02\n",
      "Iteration 7000: Cost     0.00  dj_dw: -4.657e-03, dj_db:  7.535e-03   w:  1.999e+02, b: 1.00103e+02\n",
      "Iteration 8000: Cost     0.00  dj_dw: -2.245e-03, dj_db:  3.632e-03   w:  2.000e+02, b: 1.00050e+02\n",
      "Iteration 9000: Cost     0.00  dj_dw: -1.082e-03, dj_db:  1.751e-03   w:  2.000e+02, b: 1.00024e+02\n",
      "w,b found by gradient descent: 199.99285075131766 100.011567727362\n"
     ]
    }
   ],
   "source": [
    "# initialize fitting parameters. Recall that the shape of w is (n,)\n",
    "initial_w = 0.\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "w, b, J_hist, p_hist = gradient_descent(x_train ,y_train, initial_w, initial_b,\n",
    "                     compute_cost, compute_gradient, alpha, iterations)\n",
    "print(\"w,b found by gradient descent:\", w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b7112-7a06-481e-8daf-f0852fd885ec",
   "metadata": {
    "id": "867b7112-7a06-481e-8daf-f0852fd885ec"
   },
   "source": [
    "## ðŸ“ˆ Visualizing the Learning Process: Cost Function Evolution\n",
    "\n",
    "### Understanding Your Algorithm's Journey\n",
    "\n",
    "Now comes one of the most exciting parts - watching your gradient descent algorithm learn in real time! The learning curve visualization will show you exactly how your algorithm improved with each iteration.\n",
    "\n",
    "### What You'll Observe in the Plots\n",
    "\n",
    "**Two-Panel Visualization:**\n",
    "\n",
    "1. **Left Panel (Early Learning):** Shows the first 100 iterations\n",
    "   \n",
    "   - **Expect:** Sharp, rapid decrease in cost\n",
    "   - **Why:** Initial parameter values are far from optimal, so big improvements happen quickly\n",
    "   - **Learning:** This demonstrates the power of gradient descent's initial convergence\n",
    "\n",
    "2. **Right Panel (Fine-Tuning):** Shows iterations 1000+ to the end\n",
    "   \n",
    "   - **Expect:** Gradual, steady decrease approaching a minimum\n",
    "   - **Why:** Algorithm is fine-tuning parameters near the optimal solution\n",
    "   - **Learning:** Shows how gradient descent achieves precision through patience\n",
    "\n",
    "### Key Learning Insights\n",
    "\n",
    "**Cost Decrease Patterns:**\n",
    "\n",
    "- **Steep drop** â†’ Your algorithm is making big improvements (far from optimum)\n",
    "- **Gradual decline** â†’ Fine-tuning phase (approaching optimum)  \n",
    "- **Plateau** â†’ Convergence achieved (found the minimum!)\n",
    "\n",
    "**What This Tells You:**\n",
    "\n",
    "- **Algorithm Health:** Consistently decreasing cost = healthy learning\n",
    "- **Learning Rate Quality:** Smooth curves = good learning rate choice\n",
    "- **Convergence Status:** Flattening curve = approaching optimal solution\n",
    "\n",
    "**For the Canvas Quiz:** Pay attention to the final cost value and how many iterations it took to converge - these observations may be part of your quiz questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41184459-21ed-4bbb-a371-24409929c056",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "41184459-21ed-4bbb-a371-24409929c056",
    "outputId": "993fe0ea-76e5-4126-851b-0571db16486c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost versus iteration\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12,4))\n",
    "ax1.plot(J_hist[:100])\n",
    "ax2.plot(1000 + np.arange(len(J_hist[1000:])), J_hist[1000:])\n",
    "ax1.set_title(\"Cost vs. iteration(start)\");  ax2.set_title(\"Cost vs. iteration (end)\")\n",
    "ax1.set_ylabel('Cost')            ;  ax2.set_ylabel('Cost')\n",
    "ax1.set_xlabel('iteration step')  ;  ax2.set_xlabel('iteration step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a840ee-f302-4c1d-8f31-b79518f24ee7",
   "metadata": {
    "id": "90a840ee-f302-4c1d-8f31-b79518f24ee7"
   },
   "source": [
    "##  Making Predictions with Your Trained Model\n",
    "\n",
    "### Task 4: Real Estate Price Prediction Challenge\n",
    "\n",
    "**The Moment of Truth!** \n",
    "Now that you have trained your model and found optimal parameters $w$ and $b$, it's time to put your **prediction machine** to work! This is where all your hard work pays off.\n",
    "\n",
    "### Understanding Your Prediction Tool\n",
    "\n",
    "**The Prediction Formula:**\n",
    "Your linear regression model makes predictions using the simple but powerful equation:\n",
    "\n",
    "$$ f_{w,b}(x^{(i)}) = wx^{(i)} + b$$\n",
    "\n",
    "**Breaking Down Each Component:**\n",
    "\n",
    "- **$w$ (slope)** = Price increase per 1000 sqft â†’ *\"How much more does each additional 1000 sqft cost?\"*\n",
    "- **$b$ (y-intercept)** = Base price when size = 0 â†’ *\"What's the starting price before considering square footage?\"*\n",
    "- **$x^{(i)}$ (input)** = House size in thousands of sqft â†’ *\"The feature we're using to predict\"*\n",
    "- **$f_{w,b}(x^{(i)})$ (output)** = Predicted price in thousands of dollars â†’ *\"Our model's best guess\"*\n",
    "\n",
    "###  Your Real Estate Consultation Challenge\n",
    "\n",
    "**The Scenario:**\n",
    "\n",
    "A potential buyer walks into your real estate office and asks:\n",
    "\n",
    "> *\"I'm interested in buying a house with exactly **1200 square feet**. Based on recent market data, what should I expect to pay?\"*\n",
    "\n",
    "**Your Mission:**\n",
    "\n",
    "1. **Use your trained parameters** $(w, b)$ found by gradient descent\n",
    "2. **Convert units properly** (1200 sqft â†’ thousands of sqft)\n",
    "3. **Calculate the prediction** using your linear model\n",
    "4. **Provide a professional estimate** to your client\n",
    "\n",
    "\n",
    "**For the Canvas Quiz:** ðŸ“ Record your predicted price carefully - you'll need this exact number for the quiz questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "SF2ScjY1RYJ8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF2ScjY1RYJ8",
    "outputId": "6c2211ce-6bba-4eae-c560-ad7e3203d795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340.00298862894317\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# House size: 1200 sqft\n",
    "print(w * 1.2 + b)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccd1ed",
   "metadata": {},
   "source": [
    "##  Bonus Exploration: Learning Rate Sensitivity Analysis\n",
    "\n",
    "**Experiment Goal:** Run the following code cells and investigate how different learning rates affect gradient descent convergence and performance\n",
    "\n",
    "###  The Learning Rate Experiment\n",
    "\n",
    "Learning rate (Î±) is one of the most critical hyperparameters in machine learning. This experiment will demonstrate how this single parameter can dramatically affect your algorithm's behavior, convergence speed, and final performance.\n",
    "\n",
    "###  Experimental Design\n",
    "\n",
    "**Test Parameters:**\n",
    "- Learning rates: 0.001, 0.01, 0.1, 0.5\n",
    "- Iterations: 1000 (sufficient to observe different behaviors)\n",
    "- Initial conditions: w=0, b=0 (same for all tests)\n",
    "- Metric: Cost function evolution over time\n",
    "\n",
    "**Hypothesis:** Different learning rates will show distinct convergence patterns - some too slow, some too fast, and hopefully one \"just right\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using different learning rates to compare convergence behavior\n",
    "# This helps understand how learning rate affects training dynamics\n",
    "\n",
    "# Define different learning rates to test\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5]\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "iterations = 1000\n",
    "\n",
    "# Store results for each learning rate\n",
    "results = {}\n",
    "\n",
    "print(\"Testing different learning rates:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    print(f\"\\nTesting learning rate: {alpha}\")\n",
    "    \n",
    "    # Reset initial parameters for fair comparison\n",
    "    initial_w = 0.0\n",
    "    initial_b = 0.0\n",
    "    \n",
    "    # Run gradient descent with current learning rate\n",
    "    w_final, b_final, J_history, p_history = gradient_descent(\n",
    "        x_train, y_train, initial_w, initial_b, \n",
    "        compute_cost, compute_gradient, alpha, iterations\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    results[alpha] = {\n",
    "        'w': w_final,\n",
    "        'b': b_final,\n",
    "        'cost_history': J_history,\n",
    "        'final_cost': J_history[-1] if J_history else float('inf')\n",
    "    }\n",
    "    \n",
    "    print(f\"Final parameters: w={w_final:.6f}, b={b_final:.6f}\")\n",
    "    print(f\"Final cost: {J_history[-1]:.8f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Learning Rate Comparison Summary:\")\n",
    "for alpha in learning_rates:\n",
    "    result = results[alpha]\n",
    "    print(f\"Î± = {alpha:5.3f}: Final Cost = {result['final_cost']:.8f}, w = {result['w']:.6f}, b = {result['b']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3183e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization of learning curves\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: All learning curves together (full range)\n",
    "ax1.set_title('Learning Curves: All Learning Rates (Full Range)', fontsize=14, fontweight='bold')\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    cost_history = results[alpha]['cost_history']\n",
    "    ax1.plot(cost_history, color=colors[i], label=f'Î± = {alpha}', linewidth=2)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Cost J(w,b)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Early iterations (first 100) - shows initial convergence behavior\n",
    "ax2.set_title('Early Learning Phase (First 100 Iterations)', fontsize=14, fontweight='bold')\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    cost_history = results[alpha]['cost_history']\n",
    "    early_history = cost_history[:min(100, len(cost_history))]\n",
    "    ax2.plot(early_history, color=colors[i], label=f'Î± = {alpha}', linewidth=2)\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Cost J(w,b)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Log scale view - better for comparing convergence rates\n",
    "ax3.set_title('Learning Curves (Log Scale) - Convergence Analysis', fontsize=14, fontweight='bold')\n",
    "for i, alpha in enumerate(learning_rates):\n",
    "    cost_history = results[alpha]['cost_history']\n",
    "    # Add small epsilon to avoid log(0) issues\n",
    "    log_costs = [max(cost, 1e-10) for cost in cost_history]\n",
    "    ax3.semilogy(log_costs, color=colors[i], label=f'Î± = {alpha}', linewidth=2)\n",
    "ax3.set_xlabel('Iteration')\n",
    "ax3.set_ylabel('Cost J(w,b) (Log Scale)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Final cost comparison (bar chart)\n",
    "ax4.set_title('Final Cost Comparison After 1000 Iterations', fontsize=14, fontweight='bold')\n",
    "final_costs = [results[alpha]['final_cost'] for alpha in learning_rates]\n",
    "bars = ax4.bar(range(len(learning_rates)), final_costs, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Learning Rate')\n",
    "ax4.set_ylabel('Final Cost')\n",
    "ax4.set_xticks(range(len(learning_rates)))\n",
    "ax4.set_xticklabels([f'Î± = {alpha}' for alpha in learning_rates])\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, cost) in enumerate(zip(bars, final_costs)):\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(final_costs)*0.01, \n",
    "             f'{cost:.6f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis and insights\n",
    "print(\"\\nðŸ” LEARNING RATE ANALYSIS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find best performing learning rate\n",
    "best_alpha = min(learning_rates, key=lambda x: results[x]['final_cost'])\n",
    "worst_alpha = max(learning_rates, key=lambda x: results[x]['final_cost'])\n",
    "\n",
    "print(f\"ðŸ† BEST Learning Rate: Î± = {best_alpha}\")\n",
    "print(f\"   Final Cost: {results[best_alpha]['final_cost']:.8f}\")\n",
    "print(f\"   Parameters: w = {results[best_alpha]['w']:.6f}, b = {results[best_alpha]['b']:.6f}\")\n",
    "\n",
    "print(f\"\\nâŒ WORST Learning Rate: Î± = {worst_alpha}\")\n",
    "print(f\"   Final Cost: {results[worst_alpha]['final_cost']:.8f}\")\n",
    "print(f\"   Parameters: w = {results[worst_alpha]['w']:.6f}, b = {results[worst_alpha]['b']:.6f}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "print(\"   â€¢ Lower learning rates â†’ More stable but slower convergence\")\n",
    "print(\"   â€¢ Higher learning rates â†’ Faster initial progress but may overshoot\")\n",
    "print(\"   â€¢ Optimal learning rate balances speed and stability\")\n",
    "print(\"   â€¢ Learning rate choice significantly impacts training efficiency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c009e",
   "metadata": {},
   "source": [
    "###  Your Insights and Reflection\n",
    "\n",
    "**Analyze the results above and answer these questions:**\n",
    "\n",
    "####  Observation Questions:\n",
    "\n",
    "1. **Which learning rate achieved the lowest final cost? Why do you think this happened?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "   \n",
    "2. **Compare the convergence speed between Î±=0.001 and Î±=0.1. What trade-offs do you observe?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "   \n",
    "3. **Looking at the early convergence plot (first 100 iterations), which learning rate made the most dramatic initial progress? Was this rate also the best overall performer?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "####  Critical Thinking Questions:\n",
    "\n",
    "4. **If you had to choose ONE learning rate for a production machine learning system, which would you choose and why?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "5. **What would you expect to happen if we tested an even larger learning rate like Î±=1.0? Explain your reasoning.**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "6. **How might the optimal learning rate change if we had:**\n",
    "   - A much larger dataset (1000s of examples)?\n",
    "   - A more complex cost function landscape?\n",
    "   \n",
    "   *Your answers:*\n",
    "   \n",
    "\n",
    "####  Real-World Application:\n",
    "\n",
    "7. **You're a data scientist at a real estate company. Based on this experiment, what would you tell your manager about the importance of learning rate tuning?**\n",
    "\n",
    "   *Your answer:*\n",
    "   \n",
    "\n",
    "###  Key Takeaways\n",
    "\n",
    "Write 3-5 bullet points summarizing the most important lessons from this learning rate sensitivity analysis:\n",
    "\n",
    "- *Your takeaway 1:*\n",
    "- *Your takeaway 2:*  \n",
    "- *Your takeaway 3:*\n",
    "- *Your takeaway 4:*\n",
    "- *Your takeaway 5:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344729aa-f0e6-4910-b08a-c0c667c964fc",
   "metadata": {
    "id": "344729aa-f0e6-4910-b08a-c0c667c964fc"
   },
   "source": [
    "## ðŸ† Congratulations! You've Mastered Gradient Descent!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "In this quiz, you successfully:\n",
    "\n",
    "**ðŸ”¬ Built from Scratch:**\n",
    "\n",
    "- Cost function using Mean Squared Error\n",
    "- Gradient calculations with partial derivatives  \n",
    "- Complete gradient descent optimization algorithm\n",
    "\n",
    "**ðŸ  Solved Real Problems:**\n",
    "\n",
    "- Predicted house prices using machine learning\n",
    "- Trained a model on actual data\n",
    "- Made business-ready predictions\n",
    "\n",
    "**ðŸ“Š Understood the Process:**\n",
    "\n",
    "- Visualized algorithm learning through cost plots\n",
    "- Observed parameter convergence in real-time\n",
    "- Connected math to practical applications\n",
    "\n",
    "\n",
    "### Next Steps in Your Learning Journey\n",
    "\n",
    "You're now ready for:\n",
    "\n",
    "- **Multi-variable regression** and beyond!\n",
    "- **Vectorized implementations** for better performance\n",
    "- **Advanced algorithms** (Adam, RMSprop, etc.)\n",
    "\n",
    "\n",
    "**Key Insight:** Every advanced ML algorithm builds on these fundamentals you've mastered!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfdab3-e6d8-426f-8699-cd01f763d538",
   "metadata": {
    "id": "1dcfdab3-e6d8-426f-8699-cd01f763d538"
   },
   "source": [
    "## Reference\n",
    "\n",
    "https://www.deeplearning.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f328376-71d5-46af-883d-06d9feba7383",
   "metadata": {
    "id": "0f328376-71d5-46af-883d-06d9feba7383"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "stat362-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
